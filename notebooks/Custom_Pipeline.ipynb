{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom pipeline\n",
    "\n",
    "In this tutorial we will discuss how to create a pipeline with special components for text extraction. \n",
    "\n",
    "This extensive tutorial already discusses many of the core components of this package.\n",
    "\n",
    "**Suppose we want to perform text extraction from complex structured documents. The documents essentially consist of text blocks and titles. There are no tables.\n",
    "We want to use the OCR payment service from AWS Textract. We also want to have a reading order for the text block, as the documents contain multiple columns. A JSON file is to be output that contains all layout and text extractions including the original image.**\n",
    "\n",
    "## Processing steps\n",
    "\n",
    "To continue we need to set a processing order. For the construction of the pipeline, we carry out the following steps.\n",
    "\n",
    "- Calling up the Textract OCR service \n",
    "- Calling up the layout analysis\n",
    "- Assignment of the words bounding boxes to the bounding boxes of the layouts determined.\n",
    "- Determination of the reading order both on the level of the blocks of the layout analysis and on the       level of the word within a block.\n",
    "\n",
    "## Pipeline component OCR service\n",
    "\n",
    "A pipeline component is a building block that carries out certain steps to accomplish a task.\n",
    "\n",
    "The TextExtractionService is a component that calls a selected OCR service and transforms the returned results into the internal data model. The OCR Detector is provided when the component is initialized. It is important to note that a pipeline component and a detector are two different things. This allows a certain flexibility in the composition of pipelines.\n",
    "\n",
    "Important! Textract is an AWS paid service and you will need an AWS account to call textract client. Alternatively, you can also instantiate a free OCR service like Tesseract.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deep_doctection.extern import TextractOcrDetector\n",
    "from deep_doctection.pipe import TextExtractionService, DoctectionPipe\n",
    "from deep_doctection.utils.systools import get_package_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_detector = TextractOcrDetector()\n",
    "textract_service = TextExtractionService(ocr_detector,None)\n",
    "pipeline_component_list = [textract_service]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "We use the DoctectionPipe, which already contains functions for loading and outputting the extracts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DoctectionPipe(pipeline_component_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(get_package_path(),\"notebooks/pics/samples/sample_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_3/sample_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the pipeline by calling the analyze method and want the results returned as image. The image object is the core object where everything grapped from detectors and pipeline components is stored. \n",
    "\n",
    "Note, that the default output \"page\" will not return anything, as this type requires additional layout detections which we will adress later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1215 15:52:54 @common.py:558]\u001b[0m [JoinData] Size check failed for the list of dataflow to be joined!\n",
      "processing sample_3.png\n"
     ]
    }
   ],
   "source": [
    "df = pipeline.analyze(path=path, output=\"image\")\n",
    "doc = next(iter(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not make much sense to dig deeper into the image structure. It important to know, that it captures all fine graded information from the OCR result in an ImageAnnotation object. E.g. each single word is stored with some uuid, bounding box and value (the actual text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageAnnotation(active=True, annotation_id='172d1585-9e41-3e79-b7ac-65c81e55340f', category_name='WORD', category_id='1', score=0.9716712951660156, sub_categories={'CHARS': ContainerAnnotation(active=True, annotation_id='3bb03560-00ea-3a21-bab9-c3aa0ec938d3', category_name='CHARS', category_id='None', score=None, sub_categories={}, relationships={}, value='Anleihemärkte'), 'BLOCK': CategoryAnnotation(active=True, annotation_id='b7f36a28-09b4-3954-a002-9064471c365e', category_name='BLOCK', category_id='None', score=None, sub_categories={}, relationships={}), 'LINE': CategoryAnnotation(active=True, annotation_id='f152b47f-61f9-31b3-9904-bfc52a47c003', category_name='LINE', category_id='None', score=None, sub_categories={}, relationships={})}, relationships={}, bounding_box=BoundingBox(absolute_coords=True, ulx=137.22318817675114, uly=155.71465119719505, lrx=474.8347396850586, lry=196.48566928505898, height=40.77101808786392, width=337.61155150830746))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.annotations), doc.annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layout elements\n",
    "\n",
    "The information so far does not help much. An arrangement of the word coordinates from left to right would not result in a meaningful reading order, as the layout incorporates several columns. Rather, one has to determine additional text blocks that frame individual columns. A built-in layout detector and the associated ImageLayoutService as a pipeline component are suitable for this.\n",
    "\n",
    "We use the model config and the weights of the built-in analyzer. Make sure that the layout model weights have been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_doctection.extern import TPFrcnnDetector    \n",
    "from deep_doctection.pipe import ImageLayoutService\n",
    "from deep_doctection.utils.systools import get_weights_dir_path, get_configs_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml_path = os.path.join(get_configs_dir_path(),\"tp/layout/conf_frcnn_layout.yaml\")\n",
    "weights_path = os.path.join(get_weights_dir_path(),\"layout/model-2026500.data-00000-of-00001\")\n",
    "categories_layout = {\"1\": \"TEXT\", \"2\": \"TITLE\", \"3\": \"LIST\", \"4\": \"TABLE\", \"5\": \"FIGURE\"}\n",
    "layout_detector = TPFrcnnDetector(config_yaml_path,weights_path,categories_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageLayoutService does need a detector and an additional attribute that we will not discuss here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_service = ImageLayoutService(layout_detector,to_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting text and layouts are independent tasks, hence the can be placed in any order within the component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_component_list.append(layout_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rebuild a new pipeline and start the process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DoctectionPipe(pipeline_component_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1215 19:18:14 @common.py:558]\u001b[0m [JoinData] Size check failed for the list of dataflow to be joined!\n",
      "processing sample_3.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(561,\n",
       " ImageAnnotation(active=True, annotation_id='172d1585-9e41-3e79-b7ac-65c81e55340f', category_name='WORD', category_id='1', score=0.9716712951660156, sub_categories={'CHARS': ContainerAnnotation(active=True, annotation_id='3bb03560-00ea-3a21-bab9-c3aa0ec938d3', category_name='CHARS', category_id='None', score=None, sub_categories={}, relationships={}, value='Anleihemärkte'), 'BLOCK': CategoryAnnotation(active=True, annotation_id='b7f36a28-09b4-3954-a002-9064471c365e', category_name='BLOCK', category_id='None', score=None, sub_categories={}, relationships={}), 'LINE': CategoryAnnotation(active=True, annotation_id='f152b47f-61f9-31b3-9904-bfc52a47c003', category_name='LINE', category_id='None', score=None, sub_categories={}, relationships={})}, relationships={}, bounding_box=BoundingBox(absolute_coords=True, ulx=137.22318817675114, uly=155.71465119719505, lrx=474.8347396850586, lry=196.48566928505898, height=40.77101808786392, width=337.61155150830746)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline.analyze(path=path, output=\"image\")\n",
    "doc = next(iter(df))\n",
    "len(doc.annotations), doc.annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add matching and reading order\n",
    "\n",
    "Now, that layout and words can be extracted we now have to assign each detected word to a text box (if this is possible). For that we use the pre built MatchingService. In our configuration child categories have to be mapped to parent categories. We use a intersection over are matching rule with a threshold of 0.9. In other terms, if a word box overlays with at least 0.9 of its area to a text block it will be assigned to that box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_doctection.pipe import MatchingService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_service = MatchingService(parent_categories=[\"TEXT\",\"TITLE\",\"CELL\",\"LIST\",\"TABLE\",\"FIGURE\"],\n",
    "                        child_categories=\"WORD\",\n",
    "                        matching_rule=\"ioa\",\n",
    "                        ioa_threshold=0.9)\n",
    "\n",
    "pipeline_component_list.append(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading order service has a straight forward setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_doctection.pipe import TextOrderService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_order_service = TextOrderService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_component_list.append(reading_order_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DoctectionPipe(pipeline_component_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can eventually fire up the custom build analyzer. As we have everything we need to build the lightweight page object we can change the output accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.analyze(path=path, output=\"page\")\n",
    "doc = next(iter(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc",
   "language": "python",
   "name": "deep-doc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
