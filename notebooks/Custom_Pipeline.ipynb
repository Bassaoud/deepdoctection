{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom pipeline\n",
    "\n",
    "In this tutorial we will discuss how to create a pipeline with special components for text extraction. \n",
    "\n",
    "This extensive tutorial already discusses many of the core components of this package.\n",
    "\n",
    "We formulate the requirement as follows:\n",
    "\n",
    "**Suppose we want to perform text extraction from complex structured documents. The documents essentially consist of text blocks and titles. There are no tables.\n",
    "We want to use the OCR payment service from AWS Textract. We also want to have a reading order for text blocks, as the documents contain multiple columns. The analysis results are to be returned in a JSON structure that contains all layout informations as well as the full text and the original image.**\n",
    "\n",
    "## Processing steps\n",
    "\n",
    "To continue we need to set a processing order. For the construction of the pipeline, we want to carry out the following steps.\n",
    "\n",
    "- Call Textract OCR service \n",
    "- Call layout analysis\n",
    "- Assign words to layouts blocks via an intersection based rule \n",
    "- Determine reading order at the level of layout blocks and at the word level within one layout block.\n",
    "\n",
    "## Pipeline component OCR service\n",
    "\n",
    "A pipeline component is a building block that carries out certain steps to accomplish a task.\n",
    "\n",
    "TextExtractionService is a component that calls a selected OCR service and transforms the returned results into the internal data model. It is possible to plug in any OCR Detector into the pipeline component. This allows a certain flexibility with the composition of pipelines.\n",
    "\n",
    "Important! Textract is an AWS paid service and you will need an AWS account to call the client. Alternatively, you can also instantiate a open sourced OCR service like Tesseract. Just disable `TextractOcrDetector()` and uncomment the following two lines! Moreover, to allow the TextractOcrDetector to work you will need the package extension 'source-all-tf'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepdoctection.extern import TextractOcrDetector, TesseractOcrDetector\n",
    "from deepdoctection.pipe import TextExtractionService, DoctectionPipe\n",
    "from deepdoctection.utils.systools import get_package_path, get_configs_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_detector = TextractOcrDetector()\n",
    "\n",
    "#tess_ocr_config_path = os.path.join(get_configs_dir_path(),\"dd/conf_tesseract.yaml\")\n",
    "#ocr_detector = TesseractOcrDetector(tess_ocr_config_path, config_overwrite=[\"LANGUAGES=deu\"])\n",
    "\n",
    "textract_service = TextExtractionService(ocr_detector,None)\n",
    "pipeline_component_list = [textract_service]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "We use the DoctectionPipe, which already contains functions for loading and outputting the extracts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DoctectionPipe(pipeline_component_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(get_package_path(),\"notebooks/pics/samples/sample_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_3/sample_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the pipeline by calling the analyze method and want the results returned as an image. An image is the core object where everything grapped from detectors and pipeline components is stored. \n",
    "\n",
    "Note, that the default output \"page\" will not return anything, as this type requires additional layout detections which we will adress later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.analyze(path=path, output=\"image\")\n",
    "df.reset_state()\n",
    "doc = next(iter(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not make much sense to dig deeper into the image structure. It is important to know, that it captures all fine graded information from the OCR result in an ImageAnnotation object. E.g. each single word is stored with some uuid, bounding box and value (the recorded text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545,\n",
       " ImageAnnotation(active=True, _annotation_id='3be39a8e-880b-3a18-b0d7-80e05beb68f4', category_name=<LayoutType.word>, _category_name=<LayoutType.word>, category_id='1', score=0.9221703338623047, sub_categories={<WordType.characters>: ContainerAnnotation(active=True, _annotation_id='e68e2072-ff7c-3152-ab6b-d8fc6156dc02', category_name=<WordType.characters>, _category_name=<WordType.characters>, category_id='None', score=0.9221703338623047, sub_categories={}, relationships={}, value='Anleihem√§rkte')}, relationships={}, bounding_box=BoundingBox(absolute_coords=True, ulx=134.921634465456, uly=157.1062769368291, lrx=472.318872153759, lry=195.05085966736078, height=37.94458273053169, width=337.397237688303)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.annotations), doc.annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layout elements\n",
    "\n",
    "The current information does not help much so far. An arrangement of word coordinates from left to right would not result in a meaningful reading order, as the layout incorporates several columns. One rather has to determine additional text blocks that frame individual columns. A built-in layout detector and the associated ImageLayoutService as a pipeline component are suitable for this.\n",
    "\n",
    "At this point it starts to depend on whether the DL framework Tensorflow or PyTorch will be used. We assume that Tensorflow is installed, hence we need to import the Tensorflow related Detector TPFrcnnDetector. Use D2FrcnnDetector for PyTorch.\n",
    "\n",
    "We use the model config and the weights of the built-in analyzer. If you haven't got through the starter tutorial you can download weights using the ModelDownloadManager. \n",
    "\n",
    "```\n",
    "from deepdoctection.extern.model import ModelDownloadManager\n",
    "ModelDownloadManager.maybe_download_weights_and_configs(\"layout/model-800000_inf_only.data-00000-of-00001\")\n",
    "```\n",
    "\n",
    "Download `\"layout/d2_model-800000-layout.pkl\"` instead, in case you use PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdoctection.extern import TPFrcnnDetector, ModelCatalog    \n",
    "from deepdoctection.pipe import ImageLayoutService\n",
    "from deepdoctection.utils.systools import get_weights_dir_path, get_configs_dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model is downloaded from the hub, both the weights and the config file are loaded into the cache. The paths to both files are required\n",
    "in order to instantiate the detector. You can use the ModelCatalog to build the path. Moreover, the ModelCatalog\n",
    "provides a brief model card of all registered models.\n",
    "\n",
    "It is also necessary to pass a dict with the category-id/category names pairs. This mapping is standard and results from the dataset Publaynet on which this model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'layout/model-800000_inf_only.data-00000-of-00001',\n",
       " 'description': 'Tensorpack layout model for inference purposes trained on Publaynet',\n",
       " 'size': [274552244, 7907],\n",
       " 'tp_model': True,\n",
       " 'config': 'dd/tp/conf_frcnn_layout.yaml',\n",
       " 'hf_repo_id': 'deepdoctection/tp_casc_rcnn_X_32xd4_50_FPN_GN_2FC_publaynet_inference_only',\n",
       " 'hf_model_name': 'model-800000_inf_only',\n",
       " 'hf_config_file': ['conf_frcnn_layout.yaml'],\n",
       " 'urls': None,\n",
       " 'categories': {'1': <LayoutType.text>,\n",
       "  '2': <LayoutType.title>,\n",
       "  '3': <LayoutType.list>,\n",
       "  '4': <LayoutType.table>,\n",
       "  '5': <LayoutType.figure>}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = ModelCatalog.get_profile(\"layout/model-800000_inf_only.data-00000-of-00001\")\n",
    "profile.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml_path = ModelCatalog.get_full_path_configs(\"layout/model-800000_inf_only.data-00000-of-00001\")\n",
    "weights_path = ModelCatalog.get_full_path_weights(\"layout/model-800000_inf_only.data-00000-of-00001\") \n",
    "categories_layout = profile.categories\n",
    "layout_detector = TPFrcnnDetector(\"layout\", config_yaml_path,weights_path,categories_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageLayoutService does need a detector and an additional attribute that we will not discuss here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_service = ImageLayoutService(layout_detector,to_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting text and layouts are independent tasks, hence the can be placed in any order within the component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_component_list.append(layout_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rebuild a new pipeline and start the process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DoctectionPipe(pipeline_component_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.analyze(path=path, output=\"image\")\n",
    "df.reset_state()\n",
    "doc = next(iter(df))\n",
    "len(doc.annotations), doc.annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add matching and reading order\n",
    "\n",
    "Now, that layout and words can be extracted we now have to assign each detected word to a text box (if this is possible). For that we use the pre built MatchingService. In our configuration child categories have to be mapped to parent categories. We use a intersection over are matching rule with a threshold of 0.9. In other terms, if a word box overlays with at least 0.9 of its area to a text block it will be assigned to that box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdoctection.pipe import MatchingService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_service = MatchingService(parent_categories=[\"text\",\"title\",\"cell\",\"list\",\"table\",\"figure\"],\n",
    "                        child_categories=\"word\",\n",
    "                        matching_rule=\"ioa\",\n",
    "                        threshold=0.9)\n",
    "\n",
    "pipeline_component_list.append(matching_service )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading order service has a straight forward setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdoctection.pipe import TextOrderService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_order_service = TextOrderService(text_container=\"word\",floating_text_block_names=[\"text\",\"title\",\"list\"],\n",
    "                                         text_block_names=[\"text\",\"title\",\"list\",\"table\",\"figure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_component_list.append(reading_order_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DoctectionPipe(pipeline_component_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can eventually fire up the custom build analyzer. As we have everything we need to build the lightweight page object we can change the output accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.analyze(path=path, output=\"page\")\n",
    "df.reset_state()\n",
    "page = next(iter(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can eventually print the OCRed text in reading order with the get_text method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anleihem√§rkte im Gesch√§ftsjahr bis zum 31.12.2018\n",
      "Die internationalen Anleihe- m√§rkte entwickelten sich im Gesch√§ftsjahr 2018 unter- schiedlich und phasenweise sehr volatil. Dabei machte sich bei den Investoren zunehmend Nervosit√§t breit, was in steigen- den Risikopr√§mien zum Aus- druck kam. Grund hierf√ºr waren Turbulenzen auf der weltpoli- tischen B√ºhne, die die politi- schen Risiken erh√∂hten. Dazu z√§hlten unter anderem populis- tische Str√∂mungen nicht nur in den USA und Europa, auch in den Emerging Markets, wie zuletzt in Brasilien und Mexiko, wo Populisten in die Regie- rungen gew√§hlt wurden. Der eskalierende Handelskonflikt zwischen den USA einerseits sowie Europa und China ande- rerseits tat sein √ºbriges. Zudem ging Italien im Rahmen seiner Haushaltspolitik auf Konfronta- tionskurs zur Europ√§ischen Uni- on (EU). Dar√ºber hinaus verun- sicherte weiterhin der drohende Brexit die Marktteilnehmer, insbesondere dahingehend, ob der m√∂gliche Austritt des Ver- einigten K√∂nigreiches aus der EU geordnet oder ohne ein √úbereinkommen ungeordnet vollzogen wird. Im Gegensatz den politischen Unsicher- heiten standen die bislang eher zuversichtlichen, konventionel- len Wirtschaftsindikatoren So expandierte die Weltwirtschaft kr√§ftig, wenngleich sich deren Wachstum im Laufe der zwei- ten Jahresh√§lfte 2018 etwas verlangsamte. Die Geldpolitik war historisch gesehen immer noch sehr locker, trotz der welt- weit sehr hohen Verschuldung und der Zinserh√∂hungen der US-Notenbank.\n",
      "Entwicklung der Leitzinsen in den USA und im Euroraum % p. a.\n",
      "Zinswende nach Rekordtiefs bei Anleiherenditen? Im Berichtszeitraum kam es an den Anleihem√§rkten - wenn auch uneinheitlich und unter- schiedlich stark ausgepr√§gt unter Schwankungen zu stei- genden Renditen auf teilweise immer noch sehr niedrigem Niveau, begleitet von nachge- benden Kursen. Dabei konnten sich die Zinsen vor allem in den USA weiter von ihren histori- schen Tiefs l√∂sen. Gleichzeitig wurde die Zentralbankdivergenz zwischen den USA und dem Euroraum immer deutlicher. An- gesichts des Wirtschaftsbooms in den USA hob die US-Noten- bank Fed im Berichtszeitraum den Leitzins in vier Schritten weiter um einen Prozentpunkt auf einen Korridor von 2,25% 2,50% p.a. an. Die Europ√§ische Zentralbank (EZB) hingegen hielt an ihrer Nullzinspolitik fest und die Bank of Japan belie√ü ihren Leitzins bei -0,10% p.a. Die Fed begr√ºndete ihre Zinser- h√∂hungen mit der Wachstums- beschleunigung und der Voll- besch√§ftigung am Arbeitsmarkt in den USA. Zinserh√∂hungen erm√∂glichten der US-Notenbank einer √úberhitzung der US-Wirt- schaft vorzubeugen, die durch die prozyklische expansive\n",
      "Fiskalpolitik des US-Pr√§sidenten Donald Trump in Form von Steuererleichterungen und einer Erh√∂hung der Staatsausgaben noch befeuert wurde. Vor die- sem Hintergrund verzeichneten die US-Bondm√§rkte einen sp√ºr- baren Renditeanstieg, der mit merklichen Kurserm√§√üigungen einherging. Per saldo stiegen die Renditen zehnj√§hriger US- Staatsanleihen auf Jahressicht von 2,4% p.a. auf 3,1% p.a.\n",
      "Diese Entwicklung in den USA hatte auf den Euroraum jedoch nur phasenweise und partiell, insgesamt aber kaum einen zinstreibenden Effekt auf Staats- anleihen aus den europ√§ischen Kernm√§rkten wie beispielsweise Deutschland und Frankreich. So gaben zehnj√§hrige deutsche Bundesanleihen im Jahresver- lauf 2018 unter Schwankungen per saldo sogar von 0,42% p.a. auf 0,25% p. a. nach. Vielmehr standen die Anleihem√§rkte der Eurol√§nder insbeson- dere ab dem zweiten Quartal 2018 unter dem Einfluss der politischen und wirtschaftlichen Entwicklung in der Eurozone, vor allem in den L√§ndern mit hoher Verschuldung und nied- rigem Wirtschaftswachstum In den Monaten Mai und Juni\n"
     ]
    }
   ],
   "source": [
    "print(page.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to continue\n",
    "\n",
    "In the next step we recommend the tutorial **Datasets_and_Eval**. Here, the data model of the package is explained in more detail. It also explains how to evaluate the precision of models using labeled data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc-tf",
   "language": "python",
   "name": "deep-doc-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
