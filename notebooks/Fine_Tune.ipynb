{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and Fine Tuning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We show how a model can be evaluated and fine-tuned on a specific dataset.\n",
    "\n",
    "For this purpose, we want to try to improve the table extraction in the **deep**doctection analyzer as an example. To better understand what we are trying to address, we need to say a little more about processing table extraction.\n",
    "\n",
    "\n",
    "![title](./pics/dd_table.png)\n",
    "\n",
    "\n",
    "Table extraction is carried out in different stages:\n",
    "\n",
    "- Table detection\n",
    "- Cell detection\n",
    "- Row and column detection\n",
    "- Segmentation / cell labeling\n",
    "\n",
    "Tables, cells and rows / columns are recognized with object detectors (Cascade-RCNN with FPN).\n",
    "The segmentation is carried out by determining the coverage of cells to rows and columns and is rule-based.\n",
    "\n",
    "Cell recognition was carried out on the [**PubTabNet**](https://github.com/ibm-aur-nlp/PubTabNet) dataset. PubTabNet contains approx. 500K tables from the field of medical research.\n",
    "\n",
    "We want to fine tune the cell recognition on Fintabnet, a dataset which contains pages from business reports. But before doing that, we want to see if the cell recognition model inference results are similar if we switch the domain. If yes, than it will support the hypothesis, that tables from different domains (e.g. medical reports / business reports) have a different intrinsic structure so that fine tuning would actually make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from deepdoctection.datasets.instances import pubtabnet as pt\n",
    "from deepdoctection.utils import get_weights_dir_path,get_configs_dir_path\n",
    "from deepdoctection.datasets import DatasetRegistry\n",
    "from deepdoctection.eval import MetricRegistry, Evaluator\n",
    "from deepdoctection.extern.tpdetect import TPFrcnnDetector\n",
    "from deepdoctection.pipe.layout import ImageLayoutService\n",
    "from deepdoctection.extern import ModelCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will make use of the builtin datasets. We use a DatasetRegistry to be able to access the built-in dataset directly. Note, that there is no automatism to download, extract and save the datasets. We will show you how to get the required details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fintabnet', 'funsd', 'iiitar13k', 'testlayout', 'publaynet', 'pubtables1m', 'pubtabnet', 'xfund']\n"
     ]
    }
   ],
   "source": [
    "DatasetRegistry.print_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PubTabNet is a large dataset for image-based table recognition, containing 568k+ images of tabular data annotated with the corresponding HTML representation of the tables. The table images are extracted from the scientific publications included in the PubMed Central Open Access Subset (commercial use collection). Table regions are identified by matching the PDF format and the XML format of the articles in the PubMed Central Open Access Subset. More details are available in our paper 'Image-based table recognition: data, model, and evaluation'. Pubtabnet can be used for training cell detection models as well as for semantic table understanding algorithms. For detection it has cell bounding box annotations as well as precisely described table semantics like row - and column numbers and row and col spans. Moreover, every cell can be classified as header or non-header cell. The dataflow builder can also return captions of bounding boxes of rows and columns. Moreover, various filter conditions on the table structure are available: maximum cell numbers, maximal row and column numbers and their minimum equivalents can be used as filter condition\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubtabnet = DatasetRegistry.get_dataset(\"pubtabnet\")\n",
    "pubtabnet.dataset_info.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install the dataset, go to the url below and download the zip-file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dax-cdn.cdn.appdomain.cloud/dax-pubtabnet/2.0.0/pubtabnet.tar.gz?_ga=2.267291150.146828643.1629125962-1173244232.1625045842'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubtabnet.dataset_info.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to unzip and place the dataset in your local .cache directory. Once extracted the dataset ought to be in the format the no further rearraging is required. However, if you are unsure, you can get some additional information about the physical structure by call the dataset modules docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/janis/.cache/deepdoctection/datasets/pubtabnet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubtabnet.dataflow.get_workdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Module for Pubtabnet dataset. Place the dataset as follows\n",
      "\n",
      "|    pubtabnet\n",
      "|    ├── test\n",
      "|    │ ├── PMC1.png\n",
      "|    ├── train\n",
      "|    │ ├── PMC2.png\n",
      "|    ├── val\n",
      "|    │ ├── PMC3.png\n",
      "|    ├── PubTabNet_2.0.0.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pt.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a tiny fraction of annotations that is available for each datapoint. `df_dict[\"annotations\"][0]` displays all informations that are available for one cell, i.e. sub categories, like row and column number, header information and bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PMC4840965_004_00.png',\n",
       " '/home/janis/.cache/deepdoctection/datasets/pubtabnet/train/PMC4840965_004_00.png',\n",
       " 'c87ee674-4ddc-3efe-a74e-dfe25da5d7b3',\n",
       " {'active': True,\n",
       "  'annotation_id': '84cbfafb-c878-323a-afcf-6159206f2e49',\n",
       "  'category_name': 'CELL',\n",
       "  'category_id': '1',\n",
       "  'score': None,\n",
       "  'sub_categories': {'ROW_NUMBER': {'active': True,\n",
       "    'annotation_id': '37cd395e-a09d-3f73-b7e5-98c0d284c75f',\n",
       "    'category_name': 'ROW_NUMBER',\n",
       "    'category_id': '28',\n",
       "    'score': None,\n",
       "    'sub_categories': {},\n",
       "    'relationships': {}},\n",
       "   'COLUMN_NUMBER': {'active': True,\n",
       "    'annotation_id': '626c0980-5a45-3223-b7c8-39bc3648722c',\n",
       "    'category_name': 'COLUMN_NUMBER',\n",
       "    'category_id': '3',\n",
       "    'score': None,\n",
       "    'sub_categories': {},\n",
       "    'relationships': {}},\n",
       "   'ROW_SPAN': {'active': True,\n",
       "    'annotation_id': '02458dd5-e774-3cf6-a299-5546d9c63880',\n",
       "    'category_name': 'ROW_SPAN',\n",
       "    'category_id': '1',\n",
       "    'score': None,\n",
       "    'sub_categories': {},\n",
       "    'relationships': {}},\n",
       "   'COLUMN_SPAN': {'active': True,\n",
       "    'annotation_id': '87df3823-d8f8-3839-ae67-2690f1ff0379',\n",
       "    'category_name': 'COLUMN_SPAN',\n",
       "    'category_id': '1',\n",
       "    'score': None,\n",
       "    'sub_categories': {},\n",
       "    'relationships': {}},\n",
       "   'HEAD': {'active': True,\n",
       "    'annotation_id': 'e74d3746-1a19-39c2-9e29-ad3dff6e54d4',\n",
       "    'category_name': 'BODY',\n",
       "    'category_id': '<property object at 0x7fe2019db040>',\n",
       "    'score': None,\n",
       "    'sub_categories': {},\n",
       "    'relationships': {}}},\n",
       "  'relationships': {},\n",
       "  'bounding_box': {'absolute_coords': True,\n",
       "   'ulx': 336.0,\n",
       "   'uly': 381.0,\n",
       "   'lrx': 376.0,\n",
       "   'lry': 391.0},\n",
       "  'image': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pubtabnet.dataflow.build(split=\"train\")\n",
    "df.reset_state()\n",
    "df_iter = iter(df)\n",
    "df_dict = next(df_iter).as_dict()\n",
    "df_dict[\"file_name\"],df_dict[\"location\"],df_dict[\"image_id\"], df_dict[\"annotations\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and weights\n",
    "\n",
    "All pre-trained models are cataloged in the ModelCatalog. You can get a list of all pre trained models. For a specific model you can get more information about the\n",
    "model type and the Huggingface repo from its profile.\n",
    "\n",
    "To instantiate a predictor we need to pass the configs and the weights. This will depend on the DL framework you are currently using and assume, this to be Tensorflow. Hence we use `cell/model-1800000.data-00000-of-00001`. If your framework, however, is PyTorch you must choose `cell/d2_model-1800000.data-00000-of-00001`. \n",
    "\n",
    "We expect the model already to be locally available. If you haven't downloaded anything yet, you can do this using the ModelDownloadManager:\n",
    "\n",
    "`ModelDownloadManager.maybe_download_weights_and_configs(\"cell/model-1800000.data-00000-of-00001\")`\n",
    "\n",
    "We then specify the local path to the config file and the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layout/model-800000_inf_only.data-00000-of-00001',\n",
       " 'cell/model-1800000_inf_only.data-00000-of-00001',\n",
       " 'item/model-1620000_inf_only.data-00000-of-00001',\n",
       " 'item/model-1620000.data-00000-of-00001',\n",
       " 'layout/model-800000.data-00000-of-00001',\n",
       " 'cell/model-1800000.data-00000-of-00001',\n",
       " 'layout/d2_model-800000-layout.pkl',\n",
       " 'cell/d2_model-1800000-cell.pkl',\n",
       " 'item/d2_model-1620000-item.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelCatalog.get_weights_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': 'dd/tp/conf_frcnn_cell',\n",
       " 'size': [823509160, 25905],\n",
       " 'hf_repo_id': 'deepdoctection/tp_casc_rcnn_X_32xd4_50_FPN_GN_2FC_pubtabnet_c',\n",
       " 'hf_model_name': 'model-1800000',\n",
       " 'hf_config_file': ['conf_frcnn_cell.yaml'],\n",
       " 'tp_model': True,\n",
       " 'urls': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = ModelCatalog.get_profile(\"cell/model-1800000.data-00000-of-00001\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_yaml=os.path.join(get_configs_dir_path(),profile[\"config\"]+\".yaml\")\n",
    "path_weights = os.path.join(get_weights_dir_path(),\"cell/model-1800000.data-00000-of-00001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "An evaluator needs a dataset on which to run the evaluation, as well as a predictor and a metric. The predictor must be wraped into a pipeline component, which is why we use the ImageLayoutService.\n",
    "\n",
    "We take the COCO metric for the problem, but define settings that deviate from the standard. We have to consider the following issues, which differ from ordinary object detection tasks:\n",
    "\n",
    "- The objects to be identified are generally smaller\n",
    "- There are many objects to identify.\n",
    "\n",
    "Therefore, we change the maximum number of detections to consider when calculating the mean average precision and also choose a different range scale for segmenting the cells into the categories small, medium and large.\n",
    "\n",
    "We then set up the predictor, the pipeline component and the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_metric = MetricRegistry.get_metric(\"coco\")\n",
    "coco_metric.set_params(max_detections=[50,200,600], area_range=[[0,1000000],[0,200],[200,800],[800,1000000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:52:12 @varmanip.py:214]\u001b[0m Checkpoint path /home/janis/.cache/deepdoctection/weights/cell/model-1800000.data-00000-of-00001 is auto-corrected to /home/janis/.cache/deepdoctection/weights/cell/model-1800000.\n",
      "\u001b[32m[0309 17:52:12 @registry.py:80]\u001b[0m 'conv0' input: [1, 3, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:90]\u001b[0m   'conv0/gn': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:93]\u001b[0m 'conv0' output: [1, 64, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:90]\u001b[0m 'pool0': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:80]\u001b[0m 'group0/block0/conv1' input: [1, 64, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:90]\u001b[0m   'group0/block0/conv1/gn': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:93]\u001b[0m 'group0/block0/conv1' output: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:80]\u001b[0m 'group0/block0/conv2' input: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:90]\u001b[0m   'group0/block0/conv2/gn': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:93]\u001b[0m 'group0/block0/conv2' output: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:80]\u001b[0m 'group0/block0/conv3' input: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:90]\u001b[0m   'group0/block0/conv3/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:93]\u001b[0m 'group0/block0/conv3' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:12 @registry.py:80]\u001b[0m 'group0/block0/convshortcut' input: [1, 64, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block0/convshortcut/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block0/convshortcut' output: [1, 256, ?, ?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janis/Public/deepdoctection/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group0/block1/conv1' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block1/conv1/gn': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block1/conv1' output: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group0/block1/conv2' input: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block1/conv2/gn': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block1/conv2' output: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group0/block1/conv3' input: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block1/conv3/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block1/conv3' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group0/block2/conv1' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block2/conv1/gn': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block2/conv1' output: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group0/block2/conv2' input: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block2/conv2/gn': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block2/conv2' output: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group0/block2/conv3' input: [1, 128, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group0/block2/conv3/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group0/block2/conv3' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block0/conv1' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block0/conv1/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block0/conv1' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block0/conv2' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block0/conv2/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block0/conv2' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block0/conv3' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block0/conv3/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block0/conv3' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block0/convshortcut' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block0/convshortcut/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block0/convshortcut' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block1/conv1' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block1/conv1/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block1/conv1' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block1/conv2' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block1/conv2/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block1/conv2' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block1/conv3' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block1/conv3/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block1/conv3' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block2/conv1' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block2/conv1/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block2/conv1' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block2/conv2' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block2/conv2/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block2/conv2' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block2/conv3' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block2/conv3/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block2/conv3' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block3/conv1' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block3/conv1/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block3/conv1' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block3/conv2' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block3/conv2/gn': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block3/conv2' output: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group1/block3/conv3' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group1/block3/conv3/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group1/block3/conv3' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block0/conv1' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block0/conv1/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block0/conv1' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block0/conv2' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block0/conv2/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block0/conv2' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block0/conv3' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block0/conv3/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block0/conv3' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block0/convshortcut' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block0/convshortcut/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block0/convshortcut' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block1/conv1' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block1/conv1/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block1/conv1' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block1/conv2' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block1/conv2/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block1/conv2' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block1/conv3' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block1/conv3/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block1/conv3' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:80]\u001b[0m 'group2/block2/conv1' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:90]\u001b[0m   'group2/block2/conv1/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:13 @registry.py:93]\u001b[0m 'group2/block2/conv1' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block2/conv2' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block2/conv2/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block2/conv2' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block2/conv3' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block2/conv3/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block2/conv3' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block3/conv1' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block3/conv1/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block3/conv1' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block3/conv2' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block3/conv2/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block3/conv2' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block3/conv3' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block3/conv3/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block3/conv3' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block4/conv1' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block4/conv1/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block4/conv1' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block4/conv2' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block4/conv2/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block4/conv2' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block4/conv3' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block4/conv3/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block4/conv3' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block5/conv1' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block5/conv1/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block5/conv1' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block5/conv2' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block5/conv2/gn': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block5/conv2' output: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group2/block5/conv3' input: [1, 512, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group2/block5/conv3/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group2/block5/conv3' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block0/conv1' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block0/conv1/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block0/conv1' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block0/conv2' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block0/conv2/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block0/conv2' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block0/conv3' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block0/conv3/gn': [1, 2048, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block0/conv3' output: [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block0/convshortcut' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block0/convshortcut/gn': [1, 2048, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block0/convshortcut' output: [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block1/conv1' input: [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block1/conv1/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block1/conv1' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block1/conv2' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block1/conv2/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block1/conv2' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block1/conv3' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block1/conv3/gn': [1, 2048, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block1/conv3' output: [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block2/conv1' input: [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block2/conv1/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block2/conv1' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block2/conv2' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block2/conv2/gn': [1, 1024, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block2/conv2' output: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'group3/block2/conv3' input: [1, 1024, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'group3/block2/conv3/gn': [1, 2048, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'group3/block2/conv3' output: [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'fpn' input: [1, 256, ?, ?], [1, 512, ?, ?], [1, 1024, ?, ?], [1, 2048, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c3': [1, 512, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c4': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c5': [1, 2048, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_c2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_c3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_c4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_c5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_p2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_p3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_p4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/gn_p5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'fpn/maxpool_p6': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:93]\u001b[0m 'fpn' output: [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:80]\u001b[0m 'rpn' input: [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:14 @registry.py:90]\u001b[0m   'rpn/conv0': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'rpn/class': [1, 256, ?, ?] --> [1, 3, ?, ?]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'rpn/box': [1, 256, ?, ?] --> [1, 12, ?, ?]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'rpn' output: [?, ?, 3], [?, ?, 3, 4]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:80]\u001b[0m 'cascade_rcnn_stage1/head' input: [?, 256, 7, 7]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage1/head/fc6': [?, 256, 7, 7] --> [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage1/head/fc7': [?, 1024] --> [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'cascade_rcnn_stage1/head' output: [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:80]\u001b[0m 'cascade_rcnn_stage1/outputs' input: [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage1/outputs/class': [?, 1024] --> [?, 3]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage1/outputs/box': [?, 1024] --> [?, 4]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'cascade_rcnn_stage1/outputs' output: [?, 3], [?, 1, 4]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:80]\u001b[0m 'cascade_rcnn_stage2/head' input: [?, 256, 7, 7]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage2/head/fc6': [?, 256, 7, 7] --> [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage2/head/fc7': [?, 1024] --> [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'cascade_rcnn_stage2/head' output: [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:80]\u001b[0m 'cascade_rcnn_stage2/outputs' input: [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage2/outputs/class': [?, 1024] --> [?, 3]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage2/outputs/box': [?, 1024] --> [?, 4]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'cascade_rcnn_stage2/outputs' output: [?, 3], [?, 1, 4]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:80]\u001b[0m 'cascade_rcnn_stage3/head' input: [?, 256, 7, 7]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage3/head/fc6': [?, 256, 7, 7] --> [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage3/head/fc7': [?, 1024] --> [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'cascade_rcnn_stage3/head' output: [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:80]\u001b[0m 'cascade_rcnn_stage3/outputs' input: [?, 1024]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage3/outputs/class': [?, 1024] --> [?, 3]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:90]\u001b[0m   'cascade_rcnn_stage3/outputs/box': [?, 1024] --> [?, 4]\n",
      "\u001b[32m[0309 17:52:15 @registry.py:93]\u001b[0m 'cascade_rcnn_stage3/outputs' output: [?, 3], [?, 1, 4]\n",
      "\u001b[32m[0309 17:52:15 @sessinit.py:86]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, learning_rate\n",
      "\u001b[32m[0309 17:52:17 @sessinit.py:114]\u001b[0m Restoring checkpoint from /home/janis/.cache/deepdoctection/weights/cell/model-1800000 ...\n",
      "INFO:tensorflow:Restoring parameters from /home/janis/.cache/deepdoctection/weights/cell/model-1800000\n"
     ]
    }
   ],
   "source": [
    "categories = pubtabnet.dataflow.categories.get_categories(filtered=True)\n",
    "cell_detector = TPFrcnnDetector(path_config_yaml,path_weights,categories)\n",
    "\n",
    "layout_service =  ImageLayoutService(cell_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the evaluation with the `run`. max_datapoints limits the number of samples in the evaluation to 100 samples. The val split is used by default. If this is not available, it must be given as an argument along with other possible build configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:52.17 @eval.py:67]\u001b[0m \u001b[32mINF\u001b[0m Building multi threading pipeline component to increase prediction throughput. Using 2 threads\n",
      "\u001b[32m[0309 17:52:17 @varmanip.py:214]\u001b[0m Checkpoint path /home/janis/.cache/deepdoctection/weights/cell/model-1800000.data-00000-of-00001 is auto-corrected to /home/janis/.cache/deepdoctection/weights/cell/model-1800000.\n",
      "\u001b[32m[0309 17:52:19 @sessinit.py:86]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, learning_rate\n",
      "\u001b[32m[0309 17:52:20 @sessinit.py:114]\u001b[0m Restoring checkpoint from /home/janis/.cache/deepdoctection/weights/cell/model-1800000 ...\n",
      "INFO:tensorflow:Restoring parameters from /home/janis/.cache/deepdoctection/weights/cell/model-1800000\n",
      "\u001b[32m[0309 17:52.20 @logger.py:193]\u001b[0m \u001b[32mINF\u001b[0m Loading annotations for 'val' split from Pubtabnet will take some time...\n",
      "\u001b[32m[0309 17:53.02 @logger.py:193]\u001b[0m \u001b[32mINF\u001b[0m dp: 549232 is malformed, err: IndexError,\n",
      "            msg: list assignment index out of range in: <frame at 0x53d5710, file '/home/janis/Public/deepdoctection/deepdoctection/mapper/pubstruct.py', line 259, code pub_to_image_uncur> will be filtered\n",
      "\u001b[32m[0309 17:53.03 @eval.py:116]\u001b[0m \u001b[32mINF\u001b[0m Predicting objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:53.14 @eval.py:121]\u001b[0m \u001b[32mINF\u001b[0m Starting evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=8.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=600 ] = 0.950\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=600 ] = 0.938\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=600 ] = 0.802\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=600 ] = 0.845\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=600 ] = 0.828\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 50 ] = 0.532\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=200 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=600 ] = 0.859\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=600 ] = 0.838\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=600 ] = 0.876\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=600 ] = 0.851\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(pubtabnet,layout_service, coco_metric)\n",
    "output= evaluator.run(category_names=[\"CELL\"],max_datapoints=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned we are now going to evaluate the cell predictor on tables from business documents. One difference from the previous evaluation is the representation of the dataset. Unlike Pubtabnet where tables are already cropped from their surronding document, the images of Fintabnet are complete document pages with embedded tables. In order to get tables only we can change the build mode, which is a specific implementation for some datasets. In this case we set `build_mode = \"table\"`. This will under the hood crop the table from the image and adjust the bounding boxes to the sub image, so that the datasets dataflow will look like the Pubtabnet dataset. For those looking closer at the configuration, they will also observe a second parameter `load_image=True`. We will not go into the details of this setting and will only refer to the fact, that an AssertionError will be raised otherwise, when using this `build_mode`. \n",
    "\n",
    "We only need to re-instantiate the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:54.22 @eval.py:67]\u001b[0m \u001b[32mINF\u001b[0m Building multi threading pipeline component to increase prediction throughput. Using 2 threads\n",
      "\u001b[32m[0309 17:54:22 @varmanip.py:214]\u001b[0m Checkpoint path /home/janis/.cache/deepdoctection/weights/cell/model-1800000.data-00000-of-00001 is auto-corrected to /home/janis/.cache/deepdoctection/weights/cell/model-1800000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. [base_layer_v1.py:1692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:54:25 @sessinit.py:86]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, learning_rate\n",
      "\u001b[32m[0309 17:54:25 @sessinit.py:114]\u001b[0m Restoring checkpoint from /home/janis/.cache/deepdoctection/weights/cell/model-1800000 ...\n",
      "INFO:tensorflow:Restoring parameters from /home/janis/.cache/deepdoctection/weights/cell/model-1800000\n",
      "\u001b[32m[0309 17:54.47 @eval.py:116]\u001b[0m \u001b[32mINF\u001b[0m Predicting objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0309 17:54.55 @eval.py:121]\u001b[0m \u001b[32mINF\u001b[0m Starting evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=600 ] = 0.902\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=600 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=600 ] = 0.555\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=600 ] = 0.559\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=600 ] = 0.690\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 50 ] = 0.587\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=200 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=600 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=600 ] = 0.631\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=600 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=600 ] = 0.763\n"
     ]
    }
   ],
   "source": [
    "fintabnet = DatasetRegistry.get_dataset(\"fintabnet\")\n",
    "fintabnet.dataflow.categories.filter_categories(categories=\"CELL\")\n",
    "\n",
    "evaluator = Evaluator(fintabnet,layout_service, coco_metric)\n",
    "output= evaluator.run(category_names=[\"CELL\"],max_datapoints=100,build_mode=\"table\",load_image=True, use_multi_proc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a certain confidence decrease for cell detection, especially for higher confidences. Note that the mAP for IoU decreases from 0.938 to 0.701 ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Tensorpack Predictor\n",
    "\n",
    "The following steps only work for Tensorpack models and not for Detectron2 models. We currently do not provide built-in training scripts for Detectron2. Also note, \n",
    "that for training/fine-tuning an already pre-trained model we must not use the inference-only weights as these do not include important checkpoint information for resuming training. \n",
    "\n",
    "For training, we use a script that stems from the training of the Faster-RCNN model from Tensorpack. We use the same model as above.\n",
    "\n",
    "We recommend to restart the kernel if you have worked through this notebook from the beginning and therefore re-import all necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepdoctection.utils import get_weights_dir_path,get_configs_dir_path\n",
    "from deepdoctection.datasets import DatasetRegistry\n",
    "from deepdoctection.eval import MetricRegistry\n",
    "from deepdoctection.extern import ModelCatalog\n",
    "from deepdoctection.train import train_faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fintabnet has a train, val and test split from which we use the first two. For each split, we need to define the dataflow built configuration. Even though not necessary, as already set by default within the training script, we explicitly pass the split.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ModelCatalog.get_profile(\"cell/model-1800000.data-00000-of-00001\")\n",
    "path_config_yaml=os.path.join(get_configs_dir_path(),profile[\"config\"]+\".yaml\")\n",
    "path_weights = os.path.join(get_weights_dir_path(),\"cell/model-1800000.data-00000-of-00001\")\n",
    "\n",
    "fintabnet = DatasetRegistry.get_dataset(\"fintabnet\")\n",
    "fintabnet.dataflow.categories.filter_categories(categories=\"CELL\")\n",
    "\n",
    "dataset_train = fintabnet\n",
    "build_train_config=[\"max_datapoints=500\",\"build_mode='table'\",\"load_image=True\", \"use_multi_proc_strict=True\",\"split='train'\"]\n",
    "\n",
    "dataset_val = fintabnet\n",
    "build_val_config = [\"max_datapoints=10\",\"build_mode='table'\",\"load_image=True\", \"use_multi_proc_strict=True\",\"split='val'\"]\n",
    "\n",
    "coco_metric = MetricRegistry.get_metric(\"coco\")\n",
    "coco_metric.set_params(max_detections=[50,200,600], area_range=[[0,1000000],[0,200],[200,800],[800,1000000]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next configs require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overwrite=[\"LR_SCHEDULE=50000\",\"TRAIN.EVAL_PERIOD=20\",\"TRAIN.CHECKPOINT_PERIOD=20\",\"BACKBONE.FREEZE_AT=0\",\"TRAIN.BASE_LR=1e-3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training. Make sure that the log directory is set correctly. If such a directory already exists, the existing one will be deleted and created again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faster_rcnn(path_config_yaml=path_config_yaml,\n",
    "                  dataset_train= dataset_train,\n",
    "                  path_weights=path_weights,\n",
    "                  config_overwrite=config_overwrite,\n",
    "                  log_dir=\"/home/janis/Documents/sample_train\",\n",
    "                  build_train_config=build_train_config,\n",
    "                  dataset_val=dataset_val,\n",
    "                  build_val_config=build_val_config,\n",
    "                  metric=coco_metric,\n",
    "                  pipeline_component_name=\"ImageLayoutService\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faster_rcnn(path_config_yaml=path_config_yaml,\n",
    "                  dataset_train=pubtabnet,\n",
    "                  path_weights=path_weights,\n",
    "                  config_overwrite=config_overwrite,\n",
    "                  log_dir=\"/path/to/log_dir\",\n",
    "                  build_train_config=build_train_config,\n",
    "                  dataset_val=dataset_val,\n",
    "                  build_val_config=build_val_config,\n",
    "                  metric=coco_metric,\n",
    "                  pipeline_component_name=\"ImageLayoutService\"\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc",
   "language": "python",
   "name": "deep-doc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
